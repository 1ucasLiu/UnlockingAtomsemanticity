{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 1,
    "llm_dtype": "torch.bfloat16",
    "lower_vram_usage": false,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "2be78c11-e463-4960-b9eb-dbf99c2dab8a",
  "datetime_epoch_millis": 1756593314982,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.08516342904314594,
      "scr_metric_threshold_2": 0.07471483005455176,
      "scr_dir2_threshold_2": 0.07471483005455176,
      "scr_dir1_threshold_5": 0.31487813530804115,
      "scr_metric_threshold_5": 0.07398496242929234,
      "scr_dir2_threshold_5": 0.07398496242929234,
      "scr_dir1_threshold_10": -0.6930270048614696,
      "scr_metric_threshold_10": 0.1596195925887888,
      "scr_dir2_threshold_10": 0.1596195925887888,
      "scr_dir1_threshold_20": -0.9985788119700915,
      "scr_metric_threshold_20": 0.1759833156057676,
      "scr_dir2_threshold_20": 0.1759833156057676,
      "scr_dir1_threshold_50": -1.4252843110347087,
      "scr_metric_threshold_50": 0.18410391436575468,
      "scr_dir2_threshold_50": 0.18410391436575468,
      "scr_dir1_threshold_100": -1.5117178101848314,
      "scr_metric_threshold_100": 0.0015773840483851165,
      "scr_dir2_threshold_100": 0.0015773840483851165,
      "scr_dir1_threshold_500": -1.963686440818274,
      "scr_metric_threshold_500": -0.3835124360328594,
      "scr_dir2_threshold_500": -0.3835124360328594
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.6428567627258455,
      "scr_metric_threshold_2": -0.038740999770529326,
      "scr_dir2_threshold_2": -0.038740999770529326,
      "scr_dir1_threshold_5": 0.5892860754104468,
      "scr_metric_threshold_5": 0.0,
      "scr_dir2_threshold_5": 0.0,
      "scr_dir1_threshold_10": 0.5357143237274155,
      "scr_metric_threshold_10": 0.06537532887188464,
      "scr_dir2_threshold_10": 0.06537532887188464,
      "scr_dir1_threshold_20": 0.5892860754104468,
      "scr_metric_threshold_20": 0.2639225918929021,
      "scr_dir2_threshold_20": 0.2639225918929021,
      "scr_dir1_threshold_50": -0.3749990686783215,
      "scr_metric_threshold_50": 0.2736076975143564,
      "scr_dir2_threshold_50": 0.2736076975143564,
      "scr_dir1_threshold_100": -0.732142305952476,
      "scr_metric_threshold_100": 0.30992742087952213,
      "scr_dir2_threshold_100": 0.30992742087952213,
      "scr_dir1_threshold_500": -1.2499986695404592,
      "scr_metric_threshold_500": 0.0629540524665211,
      "scr_dir2_threshold_500": 0.0629540524665211
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.6542055814461313,
      "scr_metric_threshold_2": 0.18208098410364867,
      "scr_dir2_threshold_2": 0.18208098410364867,
      "scr_dir1_threshold_5": 0.7476634420737516,
      "scr_metric_threshold_5": 0.1791908480345197,
      "scr_dir2_threshold_5": 0.1791908480345197,
      "scr_dir1_threshold_10": 0.7289720927693434,
      "scr_metric_threshold_10": 0.26589596371489893,
      "scr_dir2_threshold_10": 0.26589596371489893,
      "scr_dir1_threshold_20": 0.7289720927693434,
      "scr_metric_threshold_20": 0.1300578457883205,
      "scr_dir2_threshold_20": 0.1300578457883205,
      "scr_dir1_threshold_50": -0.12149544163702218,
      "scr_metric_threshold_50": -0.08092484354212127,
      "scr_dir2_threshold_50": -0.08092484354212127,
      "scr_dir1_threshold_100": 0.6355136750889335,
      "scr_metric_threshold_100": -0.3988439455723484,
      "scr_dir2_threshold_100": -0.3988439455723484,
      "scr_dir1_threshold_500": -3.18691627830803,
      "scr_metric_threshold_500": -0.41040466211661597,
      "scr_dir2_threshold_500": -0.41040466211661597
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.7272719883716677,
      "scr_metric_threshold_2": 0.03640772695984239,
      "scr_dir2_threshold_2": 0.03640772695984239,
      "scr_dir1_threshold_5": 0.5227276729653466,
      "scr_metric_threshold_5": 0.08252435471471224,
      "scr_dir2_threshold_5": 0.08252435471471224,
      "scr_dir1_threshold_10": -5.068186405525896,
      "scr_metric_threshold_10": 0.08737866044077917,
      "scr_dir2_threshold_10": 0.08737866044077917,
      "scr_dir1_threshold_20": -6.931824431689644,
      "scr_metric_threshold_20": 0.07766990431719852,
      "scr_dir2_threshold_20": 0.07766990431719852,
      "scr_dir1_threshold_50": -5.681823415700687,
      "scr_metric_threshold_50": 0.20631074211533382,
      "scr_dir2_threshold_50": 0.20631074211533382,
      "scr_dir1_threshold_100": -4.204549734014091,
      "scr_metric_threshold_100": 0.12621354026365503,
      "scr_dir2_threshold_100": 0.12621354026365503,
      "scr_dir1_threshold_500": -2.500002031977914,
      "scr_metric_threshold_500": -0.1771844737445918,
      "scr_dir2_threshold_500": -0.1771844737445918
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.2845526524801112,
      "scr_metric_threshold_2": 0.17251448636831349,
      "scr_dir2_threshold_2": 0.17251448636831349,
      "scr_dir1_threshold_5": 0.6341465896684285,
      "scr_metric_threshold_5": -0.0847954480177796,
      "scr_dir2_threshold_5": -0.0847954480177796,
      "scr_dir1_threshold_10": -2.1138221270916753,
      "scr_metric_threshold_10": 0.19005846832100343,
      "scr_dir2_threshold_10": 0.19005846832100343,
      "scr_dir1_threshold_20": -2.8211394957445664,
      "scr_metric_threshold_20": 0.13157881894967555,
      "scr_dir2_threshold_20": 0.13157881894967555,
      "scr_dir1_threshold_50": -2.8211394957445664,
      "scr_metric_threshold_50": 0.17836253844673786,
      "scr_dir2_threshold_50": 0.17836253844673786,
      "scr_dir1_threshold_100": -2.8211394957445664,
      "scr_metric_threshold_100": 0.18421041624257906,
      "scr_dir2_threshold_100": 0.18421041624257906,
      "scr_dir1_threshold_500": -2.8211394957445664,
      "scr_metric_threshold_500": -0.4473685769896797,
      "scr_dir2_threshold_500": -0.4473685769896797
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": -0.6732025303535685,
      "scr_metric_threshold_2": 0.08088218375628889,
      "scr_dir2_threshold_2": 0.08088218375628889,
      "scr_dir1_threshold_5": -0.5228757176905809,
      "scr_metric_threshold_5": 0.18382356324874222,
      "scr_dir2_threshold_5": 0.18382356324874222,
      "scr_dir1_threshold_10": -0.5032681266298754,
      "scr_metric_threshold_10": 0.18014692105869237,
      "scr_dir2_threshold_10": 0.18014692105869237,
      "scr_dir1_threshold_20": -0.5751634063314938,
      "scr_metric_threshold_20": 0.3124999041285637,
      "scr_dir2_threshold_20": 0.3124999041285637,
      "scr_dir1_threshold_50": -0.2549021899448131,
      "scr_metric_threshold_50": 0.16911765189267747,
      "scr_dir2_threshold_50": 0.16911765189267747,
      "scr_dir1_threshold_100": -0.0065358636869018594,
      "scr_metric_threshold_100": 0.38602924177417597,
      "scr_dir2_threshold_100": 0.38602924177417597,
      "scr_dir1_threshold_500": 0.2875815083793224,
      "scr_metric_threshold_500": -0.32720603461934,
      "scr_dir2_threshold_500": -0.32720603461934
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": -0.3953488049731525,
      "scr_metric_threshold_2": 0.030927845609636698,
      "scr_dir2_threshold_2": 0.030927845609636698,
      "scr_dir1_threshold_5": 0.09302343848546918,
      "scr_metric_threshold_5": 0.048109959300884644,
      "scr_dir2_threshold_5": 0.048109959300884644,
      "scr_dir1_threshold_10": 0.2868216910991789,
      "scr_metric_threshold_10": 0.14432987790265395,
      "scr_dir2_threshold_10": 0.14432987790265395,
      "scr_dir1_threshold_20": 0.4418607552416275,
      "scr_metric_threshold_20": 0.21993130104031608,
      "scr_dir2_threshold_20": 0.21993130104031608,
      "scr_dir1_threshold_50": -0.3100772041819355,
      "scr_metric_threshold_50": 0.2817867874326375,
      "scr_dir2_threshold_50": 0.2817867874326375,
      "scr_dir1_threshold_100": -1.294573528793431,
      "scr_metric_threshold_100": 0.1890034554306794,
      "scr_dir2_threshold_100": 0.1890034554306794,
      "scr_dir1_threshold_500": -2.3875969672789004,
      "scr_metric_threshold_500": -0.508591056845624,
      "scr_dir2_threshold_500": -0.508591056845624
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": -0.21848755490263158,
      "scr_metric_threshold_2": 0.10423453084937967,
      "scr_dir2_threshold_2": 0.10423453084937967,
      "scr_dir1_threshold_5": 0.3361345842626731,
      "scr_metric_threshold_5": 0.13680778533632743,
      "scr_dir2_threshold_5": 0.13680778533632743,
      "scr_dir1_threshold_10": 0.3949578485030471,
      "scr_metric_threshold_10": 0.2345277429490821,
      "scr_dir2_threshold_10": 0.2345277429490821,
      "scr_dir1_threshold_20": 0.3361345842626731,
      "scr_metric_threshold_20": 0.13355049871801492,
      "scr_dir2_threshold_20": 0.13355049871801492,
      "scr_dir1_threshold_50": -2.0,
      "scr_metric_threshold_50": 0.10423453084937967,
      "scr_dir2_threshold_50": 0.10423453084937967,
      "scr_dir1_threshold_100": -2.9243692301835873,
      "scr_metric_threshold_100": 0.02280139463201029,
      "scr_dir2_threshold_100": 0.02280139463201029,
      "scr_dir1_threshold_500": -2.3865545965943213,
      "scr_metric_threshold_500": -0.34853413365339925,
      "scr_dir2_threshold_500": -0.34853413365339925
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": -0.34054066244923537,
      "scr_metric_threshold_2": 0.029411882559833787,
      "scr_dir2_threshold_2": 0.029411882559833787,
      "scr_dir1_threshold_5": 0.11891899728879417,
      "scr_metric_threshold_5": 0.04621863681693213,
      "scr_dir2_threshold_5": 0.04621863681693213,
      "scr_dir1_threshold_10": 0.19459466425670593,
      "scr_metric_threshold_10": 0.10924377745131579,
      "scr_dir2_threshold_10": 0.10924377745131579,
      "scr_dir1_threshold_20": 0.2432433303208824,
      "scr_metric_threshold_20": 0.13865566001114957,
      "scr_dir2_threshold_20": 0.13865566001114957,
      "scr_dir1_threshold_50": 0.16216232760967658,
      "scr_metric_threshold_50": 0.34033621021703603,
      "scr_dir2_threshold_50": 0.34033621021703603,
      "scr_dir1_threshold_100": -0.7459459981925295,
      "scr_metric_threshold_100": -0.8067224512631925,
      "scr_dir2_threshold_100": -0.8067224512631925,
      "scr_dir1_threshold_500": -1.4648649954813235,
      "scr_metric_threshold_500": -0.9117646027601455,
      "scr_dir2_threshold_500": -0.9117646027601455
    }
  ],
  "sae_bench_commit_hash": "Unknown",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "fvu_only-BatchTopK-1024k-gemma-2-2b-resid_post_layer_8-5.0e+08-20250828_2222_resid_post_layer_8/trainer_0/",
  "sae_lens_version": "5.10.7",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 18432,
    "hook_layer": 8,
    "hook_name": "blocks.8.hook_resid_post",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "batch_topk",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "float32",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": -100000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}