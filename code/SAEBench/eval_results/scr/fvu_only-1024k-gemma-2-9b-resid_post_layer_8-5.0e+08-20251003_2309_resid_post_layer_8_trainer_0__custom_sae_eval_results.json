{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 1,
    "llm_dtype": "torch.bfloat16",
    "lower_vram_usage": false,
    "model_name": "google/gemma-2-9b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "4a78404c-7077-4258-995f-dd0030b44326",
  "datetime_epoch_millis": 1759808613308,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.25418145554817917,
      "scr_metric_threshold_2": 0.04844240594199542,
      "scr_dir2_threshold_2": 0.04844240594199542,
      "scr_dir1_threshold_5": 0.23101390254723733,
      "scr_metric_threshold_5": 0.10133745361853026,
      "scr_dir2_threshold_5": 0.10133745361853026,
      "scr_dir1_threshold_10": 0.39043073999106886,
      "scr_metric_threshold_10": 0.16166275007701278,
      "scr_dir2_threshold_10": 0.16166275007701278,
      "scr_dir1_threshold_20": 0.2534862913754758,
      "scr_metric_threshold_20": 0.22027140145088026,
      "scr_dir2_threshold_20": 0.22027140145088026,
      "scr_dir1_threshold_50": -0.34865118123415395,
      "scr_metric_threshold_50": 0.26169022520364027,
      "scr_dir2_threshold_50": 0.26169022520364027,
      "scr_dir1_threshold_100": -1.0304807115707493,
      "scr_metric_threshold_100": 0.22636003945489036,
      "scr_dir2_threshold_100": 0.22636003945489036,
      "scr_dir1_threshold_500": -1.7403020128756963,
      "scr_metric_threshold_500": -0.07378233443693982,
      "scr_dir2_threshold_500": -0.07378233443693982
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.6024097510321298,
      "scr_metric_threshold_2": 0.023684219607355967,
      "scr_dir2_threshold_2": 0.023684219607355967,
      "scr_dir1_threshold_5": 0.7831324609033048,
      "scr_metric_threshold_5": 0.06315786666817247,
      "scr_dir2_threshold_5": 0.06315786666817247,
      "scr_dir1_threshold_10": 0.8433733641936965,
      "scr_metric_threshold_10": 0.10526321568317433,
      "scr_dir2_threshold_10": 0.10526321568317433,
      "scr_dir1_threshold_20": 0.18072270987117497,
      "scr_metric_threshold_20": 0.17368417255105686,
      "scr_dir2_threshold_20": 0.17368417255105686,
      "scr_dir1_threshold_50": -0.9759039259351286,
      "scr_metric_threshold_50": 0.18684205490466238,
      "scr_dir2_threshold_50": 0.18684205490466238,
      "scr_dir1_threshold_100": -4.63855458025765,
      "scr_metric_threshold_100": 0.0973684235292789,
      "scr_dir2_threshold_100": 0.0973684235292789,
      "scr_dir1_threshold_500": -4.63855458025765,
      "scr_metric_threshold_500": -0.08157899607581837,
      "scr_dir2_threshold_500": -0.08157899607581837
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.6227544760575002,
      "scr_metric_threshold_2": 0.05226496611361725,
      "scr_dir2_threshold_2": 0.05226496611361725,
      "scr_dir1_threshold_5": 0.7664669376357165,
      "scr_metric_threshold_5": 0.09407668978648454,
      "scr_dir2_threshold_5": 0.09407668978648454,
      "scr_dir1_threshold_10": 0.8203591553417879,
      "scr_metric_threshold_10": 0.22299655186092138,
      "scr_dir2_threshold_10": 0.22299655186092138,
      "scr_dir1_threshold_20": 0.7724548825110751,
      "scr_metric_threshold_20": 0.19860641433203027,
      "scr_dir2_threshold_20": 0.19860641433203027,
      "scr_dir1_threshold_50": -0.7365264994310792,
      "scr_metric_threshold_50": 0.12543558638197938,
      "scr_dir2_threshold_50": 0.12543558638197938,
      "scr_dir1_threshold_100": -1.4550891642360828,
      "scr_metric_threshold_100": -0.3240417930323209,
      "scr_dir2_threshold_100": -0.3240417930323209,
      "scr_dir1_threshold_500": -1.7425144443064378,
      "scr_metric_threshold_500": -0.7212544140146927,
      "scr_dir2_threshold_500": -0.7212544140146927
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.46341472279101076,
      "scr_metric_threshold_2": 0.018372777732583244,
      "scr_dir2_threshold_2": 0.018372777732583244,
      "scr_dir1_threshold_5": 0.6951220841865161,
      "scr_metric_threshold_5": 0.06561688453908875,
      "scr_dir2_threshold_5": 0.06561688453908875,
      "scr_dir1_threshold_10": 0.7439026960939311,
      "scr_metric_threshold_10": 0.09711285144834578,
      "scr_dir2_threshold_10": 0.09711285144834578,
      "scr_dir1_threshold_20": 0.7560976673492129,
      "scr_metric_threshold_20": 0.16797901165810403,
      "scr_dir2_threshold_20": 0.16797901165810403,
      "scr_dir1_threshold_50": -0.2682930020476387,
      "scr_metric_threshold_50": 0.2493438796518213,
      "scr_dir2_threshold_50": 0.2493438796518213,
      "scr_dir1_threshold_100": -0.7926833080013462,
      "scr_metric_threshold_100": 0.3727034223387546,
      "scr_dir2_threshold_100": 0.3727034223387546,
      "scr_dir1_threshold_500": -3.756099848008077,
      "scr_metric_threshold_500": -0.27559057089040884,
      "scr_dir2_threshold_500": -0.27559057089040884
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.22807002255913755,
      "scr_metric_threshold_2": 0.013513540725275752,
      "scr_dir2_threshold_2": 0.013513540725275752,
      "scr_dir1_threshold_5": 0.47953225343197264,
      "scr_metric_threshold_5": 0.14189187556483454,
      "scr_dir2_threshold_5": 0.14189187556483454,
      "scr_dir1_threshold_10": 0.5438596063165585,
      "scr_metric_threshold_10": 0.19932437330549635,
      "scr_dir2_threshold_10": 0.19932437330549635,
      "scr_dir1_threshold_20": 0.040935841701221096,
      "scr_metric_threshold_20": 0.2736487466109927,
      "scr_dir2_threshold_20": 0.2736487466109927,
      "scr_dir1_threshold_50": -0.42690065613906913,
      "scr_metric_threshold_50": 0.375,
      "scr_dir2_threshold_50": 0.375,
      "scr_dir1_threshold_100": -0.5146198687721861,
      "scr_metric_threshold_100": 0.4020270814505515,
      "scr_dir2_threshold_100": 0.4020270814505515,
      "scr_dir1_threshold_500": -1.7368420135354825,
      "scr_metric_threshold_500": -0.35472978959560664,
      "scr_dir2_threshold_500": -0.35472978959560664
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": -0.054545487385486806,
      "scr_metric_threshold_2": 0.11475407833759727,
      "scr_dir2_threshold_2": 0.11475407833759727,
      "scr_dir1_threshold_5": -0.29090938646938125,
      "scr_metric_threshold_5": 0.1721311175063959,
      "scr_dir2_threshold_5": 0.1721311175063959,
      "scr_dir1_threshold_10": -0.2,
      "scr_metric_threshold_10": 0.25000018321098505,
      "scr_dir2_threshold_10": 0.25000018321098505,
      "scr_dir1_threshold_20": -0.5878789411322718,
      "scr_metric_threshold_20": 0.36885256914321507,
      "scr_dir2_threshold_20": 0.36885256914321507,
      "scr_dir1_threshold_50": -0.5272729243129208,
      "scr_metric_threshold_50": 0.3893443513976922,
      "scr_dir2_threshold_50": 0.3893443513976922,
      "scr_dir1_threshold_100": -0.6606063780597058,
      "scr_metric_threshold_100": 0.19262289976087302,
      "scr_dir2_threshold_100": 0.19262289976087302,
      "scr_dir1_threshold_500": -1.5515157645290871,
      "scr_metric_threshold_500": -0.6229508156675194,
      "scr_dir2_threshold_500": -0.6229508156675194
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": -0.03448230975501809,
      "scr_metric_threshold_2": 0.03194884893537162,
      "scr_dir2_threshold_2": 0.03194884893537162,
      "scr_dir1_threshold_5": -0.1149424027382507,
      "scr_metric_threshold_5": 0.07667727553092404,
      "scr_dir2_threshold_5": 0.07667727553092404,
      "scr_dir1_threshold_10": -0.1264365059899234,
      "scr_metric_threshold_10": 0.12460073936414227,
      "scr_dir2_threshold_10": 0.12460073936414227,
      "scr_dir1_threshold_20": 0.21839070222482868,
      "scr_metric_threshold_20": 0.19169328404239053,
      "scr_dir2_threshold_20": 0.19169328404239053,
      "scr_dir1_threshold_50": -0.32183900171140667,
      "scr_metric_threshold_50": 0.24920128829812374,
      "scr_dir2_threshold_50": 0.24920128829812374,
      "scr_dir1_threshold_100": 0.3678160998288593,
      "scr_metric_threshold_100": 0.3162940234065328,
      "scr_dir2_threshold_100": 0.3162940234065328,
      "scr_dir1_threshold_500": 0.43678208956041925,
      "scr_metric_threshold_500": 0.5750798521271715,
      "scr_dir2_threshold_500": 0.5750798521271715
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.24175850807545035,
      "scr_metric_threshold_2": 0.0783133179031518,
      "scr_dir2_threshold_2": 0.0783133179031518,
      "scr_dir1_threshold_5": -0.23076963384392485,
      "scr_metric_threshold_5": 0.13855422119354346,
      "scr_dir2_threshold_5": 0.13855422119354346,
      "scr_dir1_threshold_10": 0.3846151830780376,
      "scr_metric_threshold_10": 0.18072288940322828,
      "scr_dir2_threshold_10": 0.18072288940322828,
      "scr_dir1_threshold_20": 0.46153861269147184,
      "scr_metric_threshold_20": 0.286144649693467,
      "scr_dir2_threshold_20": 0.286144649693467,
      "scr_dir1_threshold_50": 0.46153861269147184,
      "scr_metric_threshold_50": 0.38554221193543453,
      "scr_dir2_threshold_50": 0.38554221193543453,
      "scr_dir1_threshold_100": -0.20879123038449598,
      "scr_metric_threshold_100": 0.5,
      "scr_dir2_threshold_100": 0.5,
      "scr_dir1_threshold_500": -0.538462042304906,
      "scr_metric_threshold_500": 0.6837348986613372,
      "scr_dir2_threshold_500": 0.6837348986613372
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": -0.03592803898929079,
      "scr_metric_threshold_2": 0.05468749818101047,
      "scr_dir2_threshold_2": 0.05468749818101047,
      "scr_dir1_threshold_5": -0.2395210927280547,
      "scr_metric_threshold_5": 0.058593698158798425,
      "scr_dir2_threshold_5": 0.058593698158798425,
      "scr_dir1_threshold_10": 0.1137724208944623,
      "scr_metric_threshold_10": 0.1132811963398089,
      "scr_dir2_threshold_10": 0.1132811963398089,
      "scr_dir1_threshold_20": 0.18562885578709362,
      "scr_metric_threshold_20": 0.10156236357578534,
      "scr_dir2_threshold_20": 0.10156236357578534,
      "scr_dir1_threshold_50": 0.005987947012540175,
      "scr_metric_threshold_50": 0.13281242905940838,
      "scr_dir2_threshold_50": 0.13281242905940838,
      "scr_dir1_threshold_100": -0.3413172626833869,
      "scr_metric_threshold_100": 0.25390625818545287,
      "scr_dir2_threshold_100": 0.25390625818545287,
      "scr_dir1_threshold_500": -0.395209499624348,
      "scr_metric_threshold_500": 0.2070311599600183,
      "scr_dir2_threshold_500": 0.2070311599600183
    }
  ],
  "sae_bench_commit_hash": "Unknown",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "fvu_only-1024k-gemma-2-9b-resid_post_layer_8-5.0e+08-20251003_2309_resid_post_layer_8/trainer_0/",
  "sae_lens_version": "5.4.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-9b",
    "d_in": 3584,
    "d_sae": 28672,
    "hook_layer": 8,
    "hook_name": "blocks.8.hook_resid_post",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "topk",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "float32",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": -100000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}