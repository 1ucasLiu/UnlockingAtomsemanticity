{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 1,
    "llm_dtype": "torch.bfloat16",
    "lower_vram_usage": false,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "b5d39178-424e-4154-9db6-d83c4ed295ae",
  "datetime_epoch_millis": 1767163111475,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.08631913756878025,
      "scr_metric_threshold_2": 0.03873492455319097,
      "scr_dir2_threshold_2": 0.03873492455319097,
      "scr_dir1_threshold_5": 0.22218930601059,
      "scr_metric_threshold_5": 0.05148390202081896,
      "scr_dir2_threshold_5": 0.05148390202081896,
      "scr_dir1_threshold_10": 0.21698245410489758,
      "scr_metric_threshold_10": 0.060215399414582704,
      "scr_dir2_threshold_10": 0.060215399414582704,
      "scr_dir1_threshold_20": 0.2730260630146915,
      "scr_metric_threshold_20": 0.07917832588478456,
      "scr_dir2_threshold_20": 0.07917832588478456,
      "scr_dir1_threshold_50": 0.2607618224347938,
      "scr_metric_threshold_50": 0.10972366235298572,
      "scr_dir2_threshold_50": 0.10972366235298572,
      "scr_dir1_threshold_100": 0.24268724081925988,
      "scr_metric_threshold_100": 0.14015406427160615,
      "scr_dir2_threshold_100": 0.14015406427160615,
      "scr_dir1_threshold_500": -0.15705489577066464,
      "scr_metric_threshold_500": 0.14477388032276298,
      "scr_dir2_threshold_500": 0.14477388032276298
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.29999980131805604,
      "scr_metric_threshold_2": 0.0,
      "scr_dir2_threshold_2": 0.0,
      "scr_dir1_threshold_5": 0.43333326710601866,
      "scr_metric_threshold_5": 0.002352910817289049,
      "scr_dir2_threshold_5": 0.002352910817289049,
      "scr_dir1_threshold_10": 0.400000397363888,
      "scr_metric_threshold_10": 0.01647051596724241,
      "scr_dir2_threshold_10": 0.01647051596724241,
      "scr_dir1_threshold_20": 0.43333326710601866,
      "scr_metric_threshold_20": 0.021176477848039575,
      "scr_dir2_threshold_20": 0.021176477848039575,
      "scr_dir1_threshold_50": 0.36666752762175725,
      "scr_metric_threshold_50": 0.035294082997992936,
      "scr_dir2_threshold_50": 0.035294082997992936,
      "scr_dir1_threshold_100": 0.5666667328939813,
      "scr_metric_threshold_100": 0.035294082997992936,
      "scr_dir2_threshold_100": 0.035294082997992936,
      "scr_dir1_threshold_500": -0.4666661368481494,
      "scr_metric_threshold_500": 0.15058825575356607,
      "scr_dir2_threshold_500": 0.15058825575356607
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.054794621212554205,
      "scr_metric_threshold_2": 0.11811012905110184,
      "scr_dir2_threshold_2": 0.11811012905110184,
      "scr_dir1_threshold_5": 0.28767155724045246,
      "scr_metric_threshold_5": 0.12073476729704187,
      "scr_dir2_threshold_5": 0.12073476729704187,
      "scr_dir1_threshold_10": 0.21917848485021682,
      "scr_metric_threshold_10": 0.10236214313281715,
      "scr_dir2_threshold_10": 0.10236214313281715,
      "scr_dir1_threshold_20": 0.30137000841813383,
      "scr_metric_threshold_20": 0.1259842002315664,
      "scr_dir2_threshold_20": 0.1259842002315664,
      "scr_dir1_threshold_50": 0.3287677272753252,
      "scr_metric_threshold_50": 0.15748032851078023,
      "scr_dir2_threshold_50": 0.15748032851078023,
      "scr_dir1_threshold_100": -0.3561638131288595,
      "scr_metric_threshold_100": 0.20734908095421878,
      "scr_dir2_threshold_100": 0.20734908095421878,
      "scr_dir1_threshold_500": -0.19178076599302543,
      "scr_metric_threshold_500": 0.09186343370641253,
      "scr_dir2_threshold_500": 0.09186343370641253
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.259258032826694,
      "scr_metric_threshold_2": 0.024570000821577526,
      "scr_dir2_threshold_2": 0.024570000821577526,
      "scr_dir1_threshold_5": 0.5185182732320055,
      "scr_metric_threshold_5": 0.03685500123236629,
      "scr_dir2_threshold_5": 0.03685500123236629,
      "scr_dir1_threshold_10": 0.5185182732320055,
      "scr_metric_threshold_10": 0.039311972024772684,
      "scr_dir2_threshold_10": 0.039311972024772684,
      "scr_dir1_threshold_20": 0.5555548196960164,
      "scr_metric_threshold_20": 0.039311972024772684,
      "scr_dir2_threshold_20": 0.039311972024772684,
      "scr_dir1_threshold_50": 0.4814817267679945,
      "scr_metric_threshold_50": 0.051596972435561446,
      "scr_dir2_threshold_50": 0.051596972435561446,
      "scr_dir1_threshold_100": 0.5555548196960164,
      "scr_metric_threshold_100": 0.0933660617014973,
      "scr_dir2_threshold_100": 0.0933660617014973,
      "scr_dir1_threshold_500": -1.4444451803039835,
      "scr_metric_threshold_500": 0.08599500287552134,
      "scr_dir2_threshold_500": 0.08599500287552134
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": -0.05376339261966274,
      "scr_metric_threshold_2": -0.0026882978130221414,
      "scr_dir2_threshold_2": -0.0026882978130221414,
      "scr_dir1_threshold_5": 0.25806441275642017,
      "scr_metric_threshold_5": 0.0,
      "scr_dir2_threshold_5": 0.0,
      "scr_dir1_threshold_10": 0.17204272820088176,
      "scr_metric_threshold_10": 0.018817123325862457,
      "scr_dir2_threshold_10": 0.018817123325862457,
      "scr_dir1_threshold_20": 0.333333546970065,
      "scr_metric_threshold_20": 0.029569833895304758,
      "scr_dir2_threshold_20": 0.029569833895304758,
      "scr_dir1_threshold_50": 0.21505357047865095,
      "scr_metric_threshold_50": 0.06720424077457843,
      "scr_dir2_threshold_50": 0.06720424077457843,
      "scr_dir1_threshold_100": 0.43010778186749693,
      "scr_metric_threshold_100": 0.0725805159455252,
      "scr_dir2_threshold_100": 0.0725805159455252,
      "scr_dir1_threshold_500": -0.0430108422777692,
      "scr_metric_threshold_500": -0.0215054211388846,
      "scr_dir2_threshold_500": -0.0215054211388846
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.0,
      "scr_metric_threshold_2": 0.06694548669432422,
      "scr_dir2_threshold_2": 0.06694548669432422,
      "scr_dir1_threshold_5": 0.027972083353132077,
      "scr_metric_threshold_5": 0.09623430857995065,
      "scr_dir2_threshold_5": 0.09623430857995065,
      "scr_dir1_threshold_10": 0.027972083353132077,
      "scr_metric_threshold_10": 0.08786596687328777,
      "scr_dir2_threshold_10": 0.08786596687328777,
      "scr_dir1_threshold_20": 0.027972083353132077,
      "scr_metric_threshold_20": 0.12970717662301062,
      "scr_dir2_threshold_20": 0.12970717662301062,
      "scr_dir1_threshold_50": 0.0769229166093545,
      "scr_metric_threshold_50": 0.16736409082350417,
      "scr_dir2_threshold_50": 0.16736409082350417,
      "scr_dir1_threshold_100": 0.04895083325622243,
      "scr_metric_threshold_100": 0.1589957491168413,
      "scr_dir2_threshold_100": 0.1589957491168413,
      "scr_dir1_threshold_500": 0.1678320833031142,
      "scr_metric_threshold_500": 0.02928857249383067,
      "scr_dir2_threshold_500": 0.02928857249383067
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.06862773743101638,
      "scr_metric_threshold_2": 0.018796972263676576,
      "scr_dir2_threshold_2": 0.018796972263676576,
      "scr_dir1_threshold_5": 0.07843153296136918,
      "scr_metric_threshold_5": 0.015037622626458184,
      "scr_dir2_threshold_5": 0.015037622626458184,
      "scr_dir1_threshold_10": 0.09803912402207475,
      "scr_metric_threshold_10": 0.04511286787937455,
      "scr_dir2_threshold_10": 0.04511286787937455,
      "scr_dir1_threshold_20": 0.11764729944205377,
      "scr_metric_threshold_20": 0.0939850853959675,
      "scr_dir2_threshold_20": 0.0939850853959675,
      "scr_dir1_threshold_50": 0.13725489050275935,
      "scr_metric_threshold_50": 0.15789492553901863,
      "scr_dir2_threshold_50": 0.15789492553901863,
      "scr_dir1_threshold_100": 0.13725489050275935,
      "scr_metric_threshold_100": 0.1766918978026952,
      "scr_dir2_threshold_100": 0.1766918978026952,
      "scr_dir1_threshold_500": 0.06862773743101638,
      "scr_metric_threshold_500": 0.2593984861318383,
      "scr_dir2_threshold_500": 0.2593984861318383
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.02654833647620429,
      "scr_metric_threshold_2": 0.038062201667444895,
      "scr_dir2_threshold_2": 0.038062201667444895,
      "scr_dir1_threshold_5": 0.11504384634657734,
      "scr_metric_threshold_5": 0.08996546643413296,
      "scr_dir2_threshold_5": 0.08996546643413296,
      "scr_dir1_threshold_10": 0.21238932918386455,
      "scr_metric_threshold_10": 0.10726648594155529,
      "scr_dir2_threshold_10": 0.10726648594155529,
      "scr_dir1_threshold_20": 0.3097342845463057,
      "scr_metric_threshold_20": 0.1245675054489776,
      "scr_dir2_threshold_20": 0.1245675054489776,
      "scr_dir1_threshold_50": 0.38053090343254253,
      "scr_metric_threshold_50": 0.14878885026160044,
      "scr_dir2_threshold_50": 0.14878885026160044,
      "scr_dir1_threshold_100": 0.4070797673835929,
      "scr_metric_threshold_100": 0.19723174613126715,
      "scr_dir2_threshold_100": 0.19723174613126715,
      "scr_dir1_threshold_500": 0.4424775493518653,
      "scr_metric_threshold_500": 0.30449823207282245,
      "scr_dir2_threshold_500": 0.30449823207282245
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.035087963905379896,
      "scr_metric_threshold_2": 0.0460829037404248,
      "scr_dir2_threshold_2": 0.0460829037404248,
      "scr_dir1_threshold_5": 0.05847947508874469,
      "scr_metric_threshold_5": 0.05069113917931274,
      "scr_dir2_threshold_5": 0.05069113917931274,
      "scr_dir1_threshold_10": 0.08771921263311704,
      "scr_metric_threshold_10": 0.06451612017174926,
      "scr_dir2_threshold_10": 0.06451612017174926,
      "scr_dir1_threshold_20": 0.10526319458580699,
      "scr_metric_threshold_20": 0.0691243556106372,
      "scr_dir2_threshold_20": 0.0691243556106372,
      "scr_dir1_threshold_50": 0.09941531678996579,
      "scr_metric_threshold_50": 0.0921658074808496,
      "scr_dir2_threshold_50": 0.0921658074808496,
      "scr_dir1_threshold_100": 0.15204691408286927,
      "scr_metric_threshold_100": 0.17972337952281128,
      "scr_dir2_threshold_100": 0.17972337952281128,
      "scr_dir1_threshold_500": 0.21052638917161398,
      "scr_metric_threshold_500": 0.25806448068699706,
      "scr_dir2_threshold_500": 0.25806448068699706
    }
  ],
  "sae_bench_commit_hash": "Unknown",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "100fvu_cos_no_eyes-1024k-BatchTopK-gemma-2-2b-resid_post_layer_4-5.0e+08-20251228_1919_resid_post_layer_4/trainer_0/",
  "sae_lens_version": "5.4.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 18432,
    "hook_layer": 4,
    "hook_name": "blocks.4.hook_resid_post",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "batch_topk",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": -100000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}