{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 1,
    "llm_dtype": "torch.bfloat16",
    "lower_vram_usage": false,
    "model_name": "google/gemma-2-2b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "66c98e21-67f7-4b14-b3ba-97ce4dededd7",
  "datetime_epoch_millis": 1767673768089,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.10477978195785274,
      "scr_metric_threshold_2": 0.03971030017875781,
      "scr_dir2_threshold_2": 0.03971030017875781,
      "scr_dir1_threshold_5": 0.180383916783321,
      "scr_metric_threshold_5": 0.07720684148134686,
      "scr_dir2_threshold_5": 0.07720684148134686,
      "scr_dir1_threshold_10": 0.18503600654059602,
      "scr_metric_threshold_10": 0.11178470967703952,
      "scr_dir2_threshold_10": 0.11178470967703952,
      "scr_dir1_threshold_20": 0.2871659437493978,
      "scr_metric_threshold_20": 0.1568519253301413,
      "scr_dir2_threshold_20": 0.1568519253301413,
      "scr_dir1_threshold_50": 0.3102762200440058,
      "scr_metric_threshold_50": 0.20348837119074403,
      "scr_dir2_threshold_50": 0.20348837119074403,
      "scr_dir1_threshold_100": 0.3054962538615178,
      "scr_metric_threshold_100": 0.242196077087298,
      "scr_dir2_threshold_100": 0.242196077087298,
      "scr_dir1_threshold_500": 0.196393017198567,
      "scr_metric_threshold_500": 0.30710464657059594,
      "scr_dir2_threshold_500": 0.30710464657059594
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.2666669315759253,
      "scr_metric_threshold_2": 0.0,
      "scr_dir2_threshold_2": 0.0,
      "scr_dir1_threshold_5": 0.36666752762175725,
      "scr_metric_threshold_5": 0.004705821634578098,
      "scr_dir2_threshold_5": 0.004705821634578098,
      "scr_dir1_threshold_10": 0.36666752762175725,
      "scr_metric_threshold_10": 0.021176477848039575,
      "scr_dir2_threshold_10": 0.021176477848039575,
      "scr_dir1_threshold_20": 0.5666667328939813,
      "scr_metric_threshold_20": 0.037646993815281984,
      "scr_dir2_threshold_20": 0.037646993815281984,
      "scr_dir1_threshold_50": 0.6333344591976826,
      "scr_metric_threshold_50": 0.0400000448787901,
      "scr_dir2_threshold_50": 0.0400000448787901,
      "scr_dir1_threshold_100": 0.5999996026361121,
      "scr_metric_threshold_100": 0.06117652272682968,
      "scr_dir2_threshold_100": 0.06117652272682968,
      "scr_dir1_threshold_500": 0.5999996026361121,
      "scr_metric_threshold_500": 0.1294117779055265,
      "scr_dir2_threshold_500": 0.1294117779055265
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.12328769360278982,
      "scr_metric_threshold_2": 0.047243957754854064,
      "scr_dir2_threshold_2": 0.047243957754854064,
      "scr_dir1_threshold_5": 0.1506854124599812,
      "scr_metric_threshold_5": 0.10236214313281715,
      "scr_dir2_threshold_5": 0.10236214313281715,
      "scr_dir1_threshold_10": 0.1643838636376626,
      "scr_metric_threshold_10": 0.14960625733031566,
      "scr_dir2_threshold_10": 0.14960625733031566,
      "scr_dir1_threshold_20": 0.38356153198605086,
      "scr_metric_threshold_20": 0.22309706687250347,
      "scr_dir2_threshold_20": 0.22309706687250347,
      "scr_dir1_threshold_50": 0.38356153198605086,
      "scr_metric_threshold_50": 0.32545921000532063,
      "scr_dir2_threshold_50": 0.32545921000532063,
      "scr_dir1_threshold_100": 0.3972607996655608,
      "scr_metric_threshold_100": 0.2834645287423466,
      "scr_dir2_threshold_100": 0.2834645287423466,
      "scr_dir1_threshold_500": -0.027396902355362823,
      "scr_metric_threshold_500": 0.3832020336292237,
      "scr_dir2_threshold_500": 0.3832020336292237
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.11111184697065024,
      "scr_metric_threshold_2": 0.01474197120319516,
      "scr_dir2_threshold_2": 0.01474197120319516,
      "scr_dir1_threshold_5": 0.37036987979734426,
      "scr_metric_threshold_5": 0.03439803043995989,
      "scr_dir2_threshold_5": 0.03439803043995989,
      "scr_dir1_threshold_10": 0.3333333333333333,
      "scr_metric_threshold_10": 0.05651106046913102,
      "scr_dir2_threshold_10": 0.05651106046913102,
      "scr_dir1_threshold_20": 0.40740642626135526,
      "scr_metric_threshold_20": 0.06633894363875661,
      "scr_dir2_threshold_20": 0.06633894363875661,
      "scr_dir1_threshold_50": 0.44444518030398356,
      "scr_metric_threshold_50": 0.0982800032863101,
      "scr_dir2_threshold_50": 0.0982800032863101,
      "scr_dir1_threshold_100": 0.37036987979734426,
      "scr_metric_threshold_100": 0.1007369740787165,
      "scr_dir2_threshold_100": 0.1007369740787165,
      "scr_dir1_threshold_500": -0.0740753005066393,
      "scr_metric_threshold_500": 0.11547909173066843,
      "scr_dir2_threshold_500": 0.11547909173066843
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.06451594296155629,
      "scr_metric_threshold_2": 0.045698819635693826,
      "scr_dir2_threshold_2": 0.045698819635693826,
      "scr_dir1_threshold_5": 0.15053762751709468,
      "scr_metric_threshold_5": 0.06989237836005181,
      "scr_dir2_threshold_5": 0.06989237836005181,
      "scr_dir1_threshold_10": 0.16129017785898822,
      "scr_metric_threshold_10": 0.0940859370844098,
      "scr_dir2_threshold_10": 0.0940859370844098,
      "scr_dir1_threshold_20": 0.36559119799574563,
      "scr_metric_threshold_20": 0.13709677936217898,
      "scr_dir2_threshold_20": 0.13709677936217898,
      "scr_dir1_threshold_50": 0.43010778186749693,
      "scr_metric_threshold_50": 0.16666661325748375,
      "scr_dir2_threshold_50": 0.16666661325748375,
      "scr_dir1_threshold_100": 0.3763437483376392,
      "scr_metric_threshold_100": 0.225806441275642,
      "scr_dir2_threshold_100": 0.225806441275642,
      "scr_dir1_threshold_500": 0.3978494899316213,
      "scr_metric_threshold_500": 0.24193542701603107,
      "scr_dir2_threshold_500": 0.24193542701603107
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.0,
      "scr_metric_threshold_2": 0.10041835473738421,
      "scr_dir2_threshold_2": 0.10041835473738421,
      "scr_dir1_threshold_5": 0.034964999987495526,
      "scr_metric_threshold_5": 0.20502100502399773,
      "scr_dir2_threshold_5": 0.20502100502399773,
      "scr_dir1_threshold_10": 0.034964999987495526,
      "scr_metric_threshold_10": 0.2761505378757555,
      "scr_dir2_threshold_10": 0.2761505378757555,
      "scr_dir1_threshold_20": 0.034964999987495526,
      "scr_metric_threshold_20": 0.34728032011930904,
      "scr_dir2_threshold_20": 0.34728032011930904,
      "scr_dir1_threshold_50": 0.006992916634363452,
      "scr_metric_threshold_50": 0.3974893727921033,
      "scr_dir2_threshold_50": 0.3974893727921033,
      "scr_dir1_threshold_100": 0.04195791662185898,
      "scr_metric_threshold_100": 0.4393305825418261,
      "scr_dir2_threshold_100": 0.4393305825418261,
      "scr_dir1_threshold_500": 0.09790208332812314,
      "scr_metric_threshold_500": 0.4518827210141268,
      "scr_dir2_threshold_500": 0.4518827210141268
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.07843153296136918,
      "scr_metric_threshold_2": 0.015037622626458184,
      "scr_dir2_threshold_2": 0.015037622626458184,
      "scr_dir1_threshold_5": 0.07843153296136918,
      "scr_metric_threshold_5": 0.02255654597847959,
      "scr_dir2_threshold_5": 0.02255654597847959,
      "scr_dir1_threshold_10": 0.10784350391170097,
      "scr_metric_threshold_10": 0.048872217516592945,
      "scr_dir2_threshold_10": 0.048872217516592945,
      "scr_dir1_threshold_20": 0.12745109497240656,
      "scr_metric_threshold_20": 0.10902270802242568,
      "scr_dir2_threshold_20": 0.10902270802242568,
      "scr_dir1_threshold_50": 0.22549021899448132,
      "scr_metric_threshold_50": 0.15037600218699723,
      "scr_dir2_threshold_50": 0.15037600218699723,
      "scr_dir1_threshold_100": 0.20588262793377574,
      "scr_metric_threshold_100": 0.22180454160448515,
      "scr_dir2_threshold_100": 0.22180454160448515,
      "scr_dir1_threshold_500": 0.03921576648068459,
      "scr_metric_threshold_500": 0.3233083262748894,
      "scr_dir2_threshold_500": 0.3233083262748894
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.14159271029762768,
      "scr_metric_threshold_2": 0.0622837527244888,
      "scr_dir2_threshold_2": 0.0622837527244888,
      "scr_dir1_threshold_5": 0.22123877467593264,
      "scr_metric_threshold_5": 0.12802766810157784,
      "scr_dir2_threshold_5": 0.12802766810157784,
      "scr_dir1_threshold_10": 0.21238932918386455,
      "scr_metric_threshold_10": 0.15570938181122201,
      "scr_dir2_threshold_10": 0.15570938181122201,
      "scr_dir1_threshold_20": 0.2654865296111192,
      "scr_metric_threshold_20": 0.2006921150282885,
      "scr_dir2_threshold_20": 0.2006921150282885,
      "scr_dir1_threshold_50": 0.1769910197407461,
      "scr_metric_threshold_50": 0.28373704991279985,
      "scr_dir2_threshold_50": 0.28373704991279985,
      "scr_dir1_threshold_100": 0.21238932918386455,
      "scr_metric_threshold_100": 0.3564012905950894,
      "scr_dir2_threshold_100": 0.3564012905950894,
      "scr_dir1_threshold_500": 0.2920353935621695,
      "scr_metric_threshold_500": 0.48442895869666724,
      "scr_dir2_threshold_500": 0.48442895869666724
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.052631597292903495,
      "scr_metric_threshold_2": 0.03225792274798828,
      "scr_dir2_threshold_2": 0.03225792274798828,
      "scr_dir1_threshold_5": 0.07017557924559344,
      "scr_metric_threshold_5": 0.05069113917931274,
      "scr_dir2_threshold_5": 0.05069113917931274,
      "scr_dir1_threshold_10": 0.09941531678996579,
      "scr_metric_threshold_10": 0.0921658074808496,
      "scr_dir2_threshold_10": 0.0921658074808496,
      "scr_dir1_threshold_20": 0.14619903628702807,
      "scr_metric_threshold_20": 0.13364047578238647,
      "scr_dir2_threshold_20": 0.13364047578238647,
      "scr_dir1_threshold_50": 0.1812866516272416,
      "scr_metric_threshold_50": 0.16589867320614746,
      "scr_dir2_threshold_50": 0.16589867320614746,
      "scr_dir1_threshold_100": 0.23976612671598632,
      "scr_metric_threshold_100": 0.2488477351334485,
      "scr_dir2_threshold_100": 0.2488477351334485,
      "scr_dir1_threshold_500": 0.24561400451182752,
      "scr_metric_threshold_500": 0.3271888362976343,
      "scr_dir2_threshold_500": 0.3271888362976343
    }
  ],
  "sae_bench_commit_hash": "Unknown",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "10fvu_nce-1024k-gemma-2-2b-resid_post_layer_4-5.0e+08-20260105_1710_resid_post_layer_4/trainer_0/",
  "sae_lens_version": "5.4.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-2b",
    "d_in": 2304,
    "d_sae": 18432,
    "hook_layer": 4,
    "hook_name": "blocks.4.hook_resid_post",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "topk",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": -100000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}