{
  "eval_type_id": "scr",
  "eval_config": {
    "random_seed": 42,
    "dataset_names": [
      "LabHC/bias_in_bios_class_set1",
      "canrager/amazon_reviews_mcauley_1and5"
    ],
    "perform_scr": true,
    "early_stopping_patience": 20,
    "train_set_size": 4000,
    "test_set_size": 1000,
    "context_length": 128,
    "probe_train_batch_size": 16,
    "probe_test_batch_size": 500,
    "probe_epochs": 20,
    "probe_lr": 0.001,
    "probe_l1_penalty": 0.001,
    "sae_batch_size": 125,
    "llm_batch_size": 1,
    "llm_dtype": "torch.bfloat16",
    "lower_vram_usage": false,
    "model_name": "google/gemma-2-9b",
    "n_values": [
      2,
      5,
      10,
      20,
      50,
      100,
      500
    ],
    "column1_vals_lookup": {
      "LabHC/bias_in_bios_class_set1": [
        [
          "professor",
          "nurse"
        ],
        [
          "architect",
          "journalist"
        ],
        [
          "surgeon",
          "psychologist"
        ],
        [
          "attorney",
          "teacher"
        ]
      ],
      "canrager/amazon_reviews_mcauley_1and5": [
        [
          "Books",
          "CDs_and_Vinyl"
        ],
        [
          "Software",
          "Electronics"
        ],
        [
          "Pet_Supplies",
          "Office_Products"
        ],
        [
          "Industrial_and_Scientific",
          "Toys_and_Games"
        ]
      ]
    }
  },
  "eval_id": "ee1153c1-1658-4ad9-8759-8867f0290859",
  "datetime_epoch_millis": 1765437960593,
  "eval_result_metrics": {
    "scr_metrics": {
      "scr_dir1_threshold_2": 0.13500747565672405,
      "scr_metric_threshold_2": 0.1019599806387726,
      "scr_dir2_threshold_2": 0.12065689405211764,
      "scr_dir1_threshold_5": 0.3022952945162326,
      "scr_metric_threshold_5": 0.1712684581133506,
      "scr_dir2_threshold_5": 0.19520785363391752,
      "scr_dir1_threshold_10": -0.13812331503839234,
      "scr_metric_threshold_10": 0.1453643550484703,
      "scr_dir2_threshold_10": 0.20345967127376902,
      "scr_dir1_threshold_20": -0.06477217400632057,
      "scr_metric_threshold_20": 0.08631476612619854,
      "scr_dir2_threshold_20": 0.1531317019531228,
      "scr_dir1_threshold_50": -0.7565414024643119,
      "scr_metric_threshold_50": 0.22577224619111547,
      "scr_dir2_threshold_50": 0.3066659327649047,
      "scr_dir1_threshold_100": -0.5183226265584843,
      "scr_metric_threshold_100": 0.22627205498401606,
      "scr_dir2_threshold_100": 0.2331064824771295,
      "scr_dir1_threshold_500": -0.842235017064796,
      "scr_metric_threshold_500": 0.2540055172180287,
      "scr_dir2_threshold_500": 0.3685564075070558
    }
  },
  "eval_result_details": [
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_professor_nurse_results",
      "scr_dir1_threshold_2": 0.3505152421976293,
      "scr_metric_threshold_2": 0.06216216651604412,
      "scr_dir2_threshold_2": 0.06216216651604412,
      "scr_dir1_threshold_5": 0.47422682946312805,
      "scr_metric_threshold_5": 0.10270266787164704,
      "scr_dir2_threshold_5": 0.10270266787164704,
      "scr_dir1_threshold_10": -1.3195878062418966,
      "scr_metric_threshold_10": 0.1891891674197794,
      "scr_dir2_threshold_10": 0.1891891674197794,
      "scr_dir1_threshold_20": -0.762886585268436,
      "scr_metric_threshold_20": 0.16216216651604412,
      "scr_dir2_threshold_20": 0.16216216651604412,
      "scr_dir1_threshold_50": -1.2577323198495751,
      "scr_metric_threshold_50": 0.24054050135560293,
      "scr_dir2_threshold_50": 0.24054050135560293,
      "scr_dir1_threshold_100": 0.45360792434511704,
      "scr_metric_threshold_100": 0.32432433303208824,
      "scr_dir2_threshold_100": 0.32432433303208824,
      "scr_dir1_threshold_500": -1.6701030484395258,
      "scr_metric_threshold_500": 0.1216216651604412,
      "scr_dir2_threshold_500": 0.1216216651604412
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_architect_journalist_results",
      "scr_dir1_threshold_2": 0.057971127166931,
      "scr_metric_threshold_2": 0.1025641270564798,
      "scr_dir2_threshold_2": 0.1025641270564798,
      "scr_dir1_threshold_5": 0.442028872833069,
      "scr_metric_threshold_5": 0.17948717458870403,
      "scr_dir2_threshold_5": 0.17948717458870403,
      "scr_dir1_threshold_10": -0.6956522302501321,
      "scr_metric_threshold_10": 0.0673075949504928,
      "scr_dir2_threshold_10": 0.0673075949504928,
      "scr_dir1_threshold_20": -0.6086955394997356,
      "scr_metric_threshold_20": -0.4615386672744303,
      "scr_dir2_threshold_20": -0.4615386672744303,
      "scr_dir1_threshold_50": 0.014492997750572723,
      "scr_metric_threshold_50": 0.051281968007968685,
      "scr_dir2_threshold_50": 0.051281968007968685,
      "scr_dir1_threshold_100": -2.173912949583113,
      "scr_metric_threshold_100": 0.01923071412292045,
      "scr_dir2_threshold_100": 0.01923071412292045,
      "scr_dir1_threshold_500": -2.1666666666666665,
      "scr_metric_threshold_500": -0.22115388105548373,
      "scr_dir2_threshold_500": -0.22115388105548373
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_surgeon_psychologist_results",
      "scr_dir1_threshold_2": 0.289855635834655,
      "scr_metric_threshold_2": 0.032663195419967136,
      "scr_dir2_threshold_2": 0.032663195419967136,
      "scr_dir1_threshold_5": 0.5072467148341263,
      "scr_metric_threshold_5": 0.07035175126832094,
      "scr_dir2_threshold_5": 0.07035175126832094,
      "scr_dir1_threshold_10": 0.27536220616640233,
      "scr_metric_threshold_10": 0.16834163704904892,
      "scr_dir2_threshold_10": 0.16834163704904892,
      "scr_dir1_threshold_20": -0.8550726140003524,
      "scr_metric_threshold_20": 0.16080389592729552,
      "scr_dir2_threshold_20": 0.16080389592729552,
      "scr_dir1_threshold_50": -3.9565214386659617,
      "scr_metric_threshold_50": 0.2713567334977503,
      "scr_dir2_threshold_50": 0.2713567334977503,
      "scr_dir1_threshold_100": -1.3768110308320116,
      "scr_metric_threshold_100": 0.2462311294391233,
      "scr_dir2_threshold_100": 0.2462311294391233,
      "scr_dir1_threshold_500": -0.8695651798332452,
      "scr_metric_threshold_500": 0.21105525380496282,
      "scr_dir2_threshold_500": 0.21105525380496282
    },
    {
      "dataset_name": "LabHC/bias_in_bios_class_set1_scr_attorney_teacher_results",
      "scr_dir1_threshold_2": 0.0,
      "scr_metric_threshold_2": 0.15562928284965422,
      "scr_dir2_threshold_2": 0.15562928284965422,
      "scr_dir1_threshold_5": 0.26543199202033624,
      "scr_metric_threshold_5": 0.26158954905737836,
      "scr_dir2_threshold_5": 0.26158954905737836,
      "scr_dir1_threshold_10": -0.08024698398658675,
      "scr_metric_threshold_10": -0.3112581709666214,
      "scr_dir2_threshold_10": -0.3112581709666214,
      "scr_dir1_threshold_20": 0.7530862880250958,
      "scr_metric_threshold_20": -0.38410589099062115,
      "scr_dir2_threshold_20": -0.38410589099062115,
      "scr_dir1_threshold_50": -1.8888892159376933,
      "scr_metric_threshold_50": -0.0033112151451037356,
      "scr_dir2_threshold_50": -0.0033112151451037356,
      "scr_dir1_threshold_100": -1.8518519199870194,
      "scr_metric_threshold_100": -0.3907283212808286,
      "scr_dir2_threshold_100": -0.3907283212808286,
      "scr_dir1_threshold_500": -1.8888892159376933,
      "scr_metric_threshold_500": 0.4735098841064831,
      "scr_dir2_threshold_500": 0.4735098841064831
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Books_CDs_and_Vinyl_results",
      "scr_dir1_threshold_2": 0.09454532922790954,
      "scr_metric_threshold_2": 0.09454532922790954,
      "scr_dir2_threshold_2": 0.25139671315384454,
      "scr_dir1_threshold_5": 0.17090907278139572,
      "scr_metric_threshold_5": 0.17090907278139572,
      "scr_dir2_threshold_5": 0.368714957301102,
      "scr_dir1_threshold_10": 0.11636366552558079,
      "scr_metric_threshold_10": 0.11636366552558079,
      "scr_dir2_threshold_10": 0.5251395048219819,
      "scr_dir1_threshold_20": 0.23272733105116158,
      "scr_metric_threshold_20": 0.23272733105116158,
      "scr_dir2_threshold_20": 0.5363128770659333,
      "scr_dir1_threshold_50": 0.14909095322790608,
      "scr_metric_threshold_50": 0.14909095322790608,
      "scr_dir2_threshold_50": 0.6145251508263734,
      "scr_dir1_threshold_100": 0.2763635701581409,
      "scr_metric_threshold_100": 0.2763635701581409,
      "scr_dir2_threshold_100": 0.2402233409098931,
      "scr_dir1_threshold_500": 0.05454540725581492,
      "scr_metric_threshold_500": 0.05454540725581492,
      "scr_dir2_threshold_500": 0.3910613688021998
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Software_Electronics_results",
      "scr_dir1_threshold_2": 0.0610329006354469,
      "scr_metric_threshold_2": 0.061983647148447805,
      "scr_dir2_threshold_2": 0.061983647148447805,
      "scr_dir1_threshold_5": 0.1549297784722634,
      "scr_metric_threshold_5": 0.17355367015534395,
      "scr_dir2_threshold_5": 0.17355367015534395,
      "scr_dir1_threshold_10": 0.19248824977305468,
      "scr_metric_threshold_10": 0.33884298538430335,
      "scr_dir2_threshold_10": 0.33884298538430335,
      "scr_dir1_threshold_20": 0.2769952999092219,
      "scr_metric_threshold_20": 0.42148776614885347,
      "scr_dir2_threshold_20": 0.42148776614885347,
      "scr_dir1_threshold_50": 0.4835681513162829,
      "scr_metric_threshold_50": 0.4958676993867373,
      "scr_dir2_threshold_50": 0.4958676993867373,
      "scr_dir1_threshold_100": 0.1502347247049711,
      "scr_metric_threshold_100": 0.33884298538430335,
      "scr_dir2_threshold_100": 0.33884298538430335,
      "scr_dir1_threshold_500": -0.8450702215277366,
      "scr_metric_threshold_500": 0.6570248371525044,
      "scr_dir2_threshold_500": 0.6570248371525044
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Pet_Supplies_Office_Products_results",
      "scr_dir1_threshold_2": 0.15044237984983322,
      "scr_metric_threshold_2": 0.23043490655029078,
      "scr_dir2_threshold_2": 0.23043490655029078,
      "scr_dir1_threshold_5": 0.2920353165415277,
      "scr_metric_threshold_5": 0.3,
      "scr_dir2_threshold_5": 0.3,
      "scr_dir1_threshold_10": 0.1991151084316568,
      "scr_metric_threshold_10": 0.3869566907503965,
      "scr_dir2_threshold_10": 0.3869566907503965,
      "scr_dir1_threshold_20": 0.23451314480156532,
      "scr_metric_threshold_20": 0.34782624470037005,
      "scr_dir2_threshold_20": 0.34782624470037005,
      "scr_dir1_threshold_50": 0.13274322979620223,
      "scr_metric_threshold_50": 0.3304349065502908,
      "scr_dir2_threshold_50": 0.3304349065502908,
      "scr_dir1_threshold_100": 0.09292020810987087,
      "scr_metric_threshold_100": 0.7130435684002114,
      "scr_dir2_threshold_100": 0.7130435684002114,
      "scr_dir1_threshold_500": 0.46460183176141473,
      "scr_metric_threshold_500": 0.552174014450238,
      "scr_dir2_threshold_500": 0.552174014450238
    },
    {
      "dataset_name": "canrager/amazon_reviews_mcauley_1and5_scr_Industrial_and_Scientific_Toys_and_Games_results",
      "scr_dir1_threshold_2": 0.0756971903413874,
      "scr_metric_threshold_2": 0.0756971903413874,
      "scr_dir2_threshold_2": 0.06842111372221286,
      "scr_dir1_threshold_5": 0.11155377918401474,
      "scr_metric_threshold_5": 0.11155377918401474,
      "scr_dir2_threshold_5": 0.105263058828844,
      "scr_dir1_threshold_10": 0.2071712702747822,
      "scr_metric_threshold_10": 0.2071712702747822,
      "scr_dir2_threshold_10": 0.26315796078077064,
      "scr_dir1_threshold_20": 0.2111552829309149,
      "scr_metric_threshold_20": 0.2111552829309149,
      "scr_dir2_threshold_20": 0.4421052235315376,
      "scr_dir1_threshold_50": 0.27091642264777144,
      "scr_metric_threshold_50": 0.27091642264777144,
      "scr_dir2_threshold_50": 0.4526317176396184,
      "scr_dir1_threshold_100": 0.2828684606161696,
      "scr_metric_threshold_100": 0.2828684606161696,
      "scr_dir2_threshold_100": 0.37368410980932476,
      "scr_dir1_threshold_500": 0.18326695686926944,
      "scr_metric_threshold_500": 0.18326695686926944,
      "scr_dir2_threshold_500": 0.763158117635101
    }
  ],
  "sae_bench_commit_hash": "Unknown",
  "sae_lens_id": "custom_sae",
  "sae_lens_release_id": "fvu_only-1024k-gemma-2-9b-resid_post_layer_25-5.0e+08-20251204_2034_resid_post_layer_25/trainer_0/",
  "sae_lens_version": "5.4.0",
  "sae_cfg_dict": {
    "model_name": "google/gemma-2-9b",
    "d_in": 3584,
    "d_sae": 28672,
    "hook_layer": 25,
    "hook_name": "blocks.25.hook_resid_post",
    "context_size": null,
    "hook_head_index": null,
    "architecture": "topk",
    "apply_b_dec_to_input": null,
    "finetuning_scaling_factor": null,
    "activation_fn_str": "",
    "prepend_bos": true,
    "normalize_activations": "none",
    "dtype": "bfloat16",
    "device": "",
    "dataset_path": "",
    "dataset_trust_remote_code": true,
    "seqpos_slice": [
      null
    ],
    "training_tokens": -100000,
    "sae_lens_training_version": null,
    "neuronpedia_id": null
  },
  "eval_result_unstructured": null
}